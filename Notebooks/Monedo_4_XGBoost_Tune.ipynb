{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78df235a",
   "metadata": {},
   "source": [
    "# 1) Read in Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38dd8a1f-8431-4f95-b1bb-e1d8700a6bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Imports.ipynb\n",
    "name = 'Kred'\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 0.3, 0.5, 1.0],\n",
    "    'max_depth': [5, 7, 10, 15, 20, 50],\n",
    "    'n_estimators': [50, 100, 200, 500, 1000],  #\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2, 0.5, 1.0],\n",
    "    'min_child_weight': [1, 3, 5, 10],\n",
    "    'reg_alpha': [0, 0.01, 0.1, 1, 10, 100],\n",
    "    'reg_lambda': [0, 0.01, 0.1, 1, 10, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56cc2917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.3'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9799522d",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_featsubgroups = pd.read_pickle('../pickle/2_FS/' + name + '/key_featsubgroups.pkl')\n",
    "df = pd.read_pickle('../pickle/2_FS/' + name + '/2_df_new_.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e381acff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.3'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d0f13a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arrears\n",
      "1   0.646\n",
      "0   0.354\n",
      "Name: count, dtype: float64\n",
      "df_shape:  (129457, 418)\n"
     ]
    }
   ],
   "source": [
    "print(df[target].value_counts() / df.shape[0])\n",
    "print('df_shape: ', df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33eba05",
   "metadata": {},
   "source": [
    "# 2) Create Model prediction functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f139308d",
   "metadata": {},
   "source": [
    "## 2.1) Split dataset into train/testing while excluding demographic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b80f656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_4(df, key_featsubgroups=key_featsubgroups, target=target, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Splits the dataset into training and testing sets while excluding demographic features.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The dataset containing features and target variable.\n",
    "    key_featsubgroups (DataFrame): A mapping of feature subgroups.\n",
    "    target (str): The name of the target variable.\n",
    "    test_size (float, optional): The proportion of the dataset to allocate for testing. Default is 0.2.\n",
    "    random_state (int, optional): Random seed for reproducibility. Default is 42.\n",
    "\n",
    "    Returns:\n",
    "    tuple: X_train, X_test, y_train, y_test (training and testing datasets)\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract demographic features\n",
    "    demo_feat = key_featsubgroups.loc[key_featsubgroups['subgroup'] == 'demo', 'list_features'].values[0]\n",
    "    print(\"Demographic Features:\", demo_feat)\n",
    "\n",
    "    # Separate features (X) and target variable (y), excluding demographic features\n",
    "    X = df.drop(columns=[target] + demo_feat)\n",
    "    y = df[target]\n",
    "\n",
    "    # Split the dataset into training (80%) and testing (20%) sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Print dataset shapes\n",
    "    print(f\"Training Features Shape: {X_train.shape}\")\n",
    "    print(f\"Training Labels Shape: {y_train.shape}\")\n",
    "    print(f\"Testing Features Shape: {X_test.shape}\")\n",
    "    print(f\"Testing Labels Shape: {y_test.shape}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3846df1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.3'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b94d2e1",
   "metadata": {},
   "source": [
    "## 2.2) Model training and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abbdda5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import types\n",
    "# import sys\n",
    "# import joblib\n",
    "# # Fake numpy._core.numeric module\n",
    "# fake_numpy_core = types.ModuleType(\"numpy._core\")\n",
    "# fake_numeric = types.ModuleType(\"numpy._core.numeric\")\n",
    "# setattr(fake_numpy_core, \"numeric\", fake_numeric)\n",
    "# sys.modules[\"numpy._core\"] = fake_numpy_core\n",
    "# sys.modules[\"numpy._core.numeric\"] = fake_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50645d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save default_params to a pickle file\n",
    "# with open('../pickle/3_Model/xgb_default_params.pkl', 'wb') as f:\n",
    "#     pickle.dump(default_params, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Save results_dict_updated to a pickle file\n",
    "# with open('../pickle/3_Model/results_dict_updated_pre-Bayes.pkl', 'wb') as f:\n",
    "#     pickle.dump(results_dict_updated, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8538f5ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.3'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0e6514f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../pickle/3_Model/xgb_default_params.pkl', 'rb') as f:\n",
    "    default_params = pickle.load(f)\n",
    "\n",
    "# Load results_dict_updated from the pickle file\n",
    "with open('../pickle/3_Model/results_dict_updated_pre-Bayes.pkl', 'rb') as f:\n",
    "    results_dict_updated = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77387554",
   "metadata": {},
   "source": [
    "# 6a) Run Bayesian hyperparameter optimization for XGBoost using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d936635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_BayesSearch_XGB_Optuna(default_params, param_grid, df, results_dict):\n",
    "    \"\"\"\n",
    "    Performs Bayesian hyperparameter optimization for an XGBoost classifier using Optuna.\n",
    "\n",
    "    This function:\n",
    "      1. Splits the input dataframe into training and testing sets.\n",
    "      2. Determines the number of iterations (n_iter) based on the parameter grid.\n",
    "      3. Unwraps default parameters from lists to their actual values.\n",
    "      4. Defines an objective function for Optuna.\n",
    "      5. Runs the Bayesian optimization using Optuna.\n",
    "      6. Evaluates the optimized model using cross-validation via the model_pred function.\n",
    "      7. Returns the updated results dictionary containing evaluation metrics.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    default_params : dict\n",
    "        Dictionary of default hyperparameters for XGBoost, with each value wrapped in a list.\n",
    "    param_grid : dict\n",
    "        The hyperparameter search space, where each parameter's possible values are provided as a list or distribution.\n",
    "    df : DataFrame\n",
    "        The dataset containing features and the target variable.\n",
    "    results_dict : dict\n",
    "        Dictionary to store the model evaluation results.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    results_dict_updated : dict\n",
    "        The updated results dictionary with model performance metrics.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 1. Split the dataset into training and testing sets.\n",
    "    X_train, X_test, y_train, y_test = split_data_4(df)\n",
    "\n",
    "    # 2. Determine the number of iterations for Bayesian optimization\n",
    "    bcvj = int(np.cumsum([len(values) for values in param_grid.values()])[-1])\n",
    "    print(\"No. of trials: \", bcvj)\n",
    "\n",
    "    # 3. Unwrap default parameters: convert each parameter's value from a list to its actual value.\n",
    "    default_params_xgb = {key: value[0] for key, value in default_params.items()}\n",
    "\n",
    "    # 4. Define the objective function for Optuna\n",
    "    def objective(trial):\n",
    "        # Build the parameters dictionary from param_grid using trial.suggest_categorical for each key\n",
    "        params = {key: trial.suggest_categorical(key, values) for key, values in param_grid.items()}\n",
    "\n",
    "        # Merge with default parameters\n",
    "        # params.update(default_params_xgb)\n",
    "\n",
    "        # Train the XGBoost model\n",
    "        xgbc = xgb.XGBClassifier(**params)\n",
    "\n",
    "        # Evaluate with cross-validation\n",
    "        accuracy = cross_val_score(xgbc, X_train, y_train, cv=5, scoring='accuracy').mean()\n",
    "\n",
    "        return accuracy\n",
    "\n",
    "    # 5. Run Bayesian Optimization using Optuna\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=bcvj)\n",
    "\n",
    "    # 6. Train the best model\n",
    "    best_params = study.best_params\n",
    "    # best_params.update(default_params_xgb)\n",
    "    best_xgbc = xgb.XGBClassifier(**best_params)\n",
    "\n",
    "    # 7. Evaluate the final model\n",
    "    results_dict = model_pred(\n",
    "        X_train, X_test, y_train, y_test, best_xgbc, 'xgbc_optuna', 'opt', results_dict\n",
    "    )\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Optimization completed in {(end_time - start_time) / 60:.2f} minutes\")\n",
    "\n",
    "    return best_params, results_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d53c0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographic Features: ['clientdata.demo.gender', 'clientdata.demo.age_year', 'clientdata.demo.age_month', 'clientdata.demo.children', 'clientdata.demo.children_singleparent', 'clientdata.demo.maritalstatus_expand_SINGLE', 'clientdata.demo.maritalstatus_expand_MARRIED', 'clientdata.demo.maritalstatus_expand_DIVORCED', 'clientdata.demo.maritalstatus_expand_WIDOWED', 'clientdata.demo.maritalstatus_expand_newvalue', 'clientdata.demo.maritalstatus_woe']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-26 12:51:21,840] A new study created in memory with name: no-name-80b667d1-3385-470c-98e7-e9d9422f077e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (103565, 406)\n",
      "Training Labels Shape: (103565,)\n",
      "Testing Features Shape: (25892, 406)\n",
      "Testing Labels Shape: (25892,)\n",
      "No. of trials:  44\n"
     ]
    }
   ],
   "source": [
    "best_params, results_dict = run_BayesSearch_XGB_Optuna(default_params, param_grid, df, results_dict_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d03eaf9-d549-4f73-9c4e-3ed6d00f248e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results_dict_updated to a pickle file\n",
    "with open('../pickle/4_Model_Optuna/results_dict_updated.pkl', 'wb') as f:\n",
    "    pickle.dump(results_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729d3649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_best_XGB(df, best_params, results_dict):\n",
    "    \"\"\"\n",
    "    Trains an XGBoost model using the best parameters found from Optuna with CV=5,\n",
    "    evaluates performance, and stores results in the given dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        The dataset containing features and the target variable.\n",
    "    best_params : dict\n",
    "        Best hyperparameters found from Optuna optimization.\n",
    "    results_dict : dict\n",
    "        Dictionary to store model performance metrics.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Updated results dictionary containing model evaluation metrics.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    print(\"\\nStarting XGBoost model training and evaluation...\")\n",
    "\n",
    "    # Split dataset\n",
    "    X_train, X_test, y_train, y_test = split_data_4(df)\n",
    "\n",
    "    # Initialize and train XGBoost with best parameters\n",
    "    xgbc = xgb.XGBClassifier(**best_params)\n",
    "    xgbc.fit(X_train, y_train)\n",
    "    fi = xgbc.feature_importances_\n",
    "\n",
    "    # Perform cross-validation with CV=5\n",
    "    y_train_pred = cross_val_predict(xgbc, X_train, y_train, cv=5)\n",
    "\n",
    "    # Make predictions on test set\n",
    "    y_test_pred = xgbc.predict(X_test)\n",
    "\n",
    "    # Compute confusion matrices\n",
    "    cfm_train = confusion_matrix(y_train, y_train_pred)\n",
    "    cfm_test = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "    # Compute accuracy scores\n",
    "    accs_train = accuracy_score(y_train, y_train_pred)\n",
    "    accs_test = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    # Compute F1-scores for both classes (0 and 1)\n",
    "    f1s_train_p1 = f1_score(y_train, y_train_pred, pos_label=1)\n",
    "    f1s_train_p0 = f1_score(y_train, y_train_pred, pos_label=0)\n",
    "    f1s_test_p1 = f1_score(y_test, y_test_pred, pos_label=1)\n",
    "    f1s_test_p0 = f1_score(y_test, y_test_pred, pos_label=0)\n",
    "\n",
    "    # Compute ROC-AUC score for test data\n",
    "    test_ras = roc_auc_score(y_test, xgbc.predict_proba(X_test)[:, 1])\n",
    "\n",
    "    # Calculate total runtime in minutes\n",
    "    total_time = (time.time() - start_time) / 60\n",
    "    print(f\"XGBoost Model training completed in {total_time:.2f} minutes\")\n",
    "\n",
    "    # Store computed values in results dictionary\n",
    "    results_dict[\"xgbc_optimized\"] = {\n",
    "        \"classifier\": deepcopy(xgbc),\n",
    "        \"cfm_train\": cfm_train,\n",
    "        \"cfm_test\": cfm_test,\n",
    "        \"train_accuracy\": accs_train,\n",
    "        \"test_accuracy\": accs_test,\n",
    "        \"train F1-score label 1\": f1s_train_p1,\n",
    "        \"train F1-score label 0\": f1s_train_p0,\n",
    "        \"test F1-score label 1\": f1s_test_p1,\n",
    "        \"test F1-score label 0\": f1s_test_p0,\n",
    "        \"test roc auc score\": test_ras,\n",
    "        \"best_params\": best_params,\n",
    "        \"feature_imp\": fi,\n",
    "        \"time_m\": total_time\n",
    "    }\n",
    "\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d679765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting XGBoost model training and evaluation...\n",
      "Demographic Features: ['clientdata.demo.gender', 'clientdata.demo.age_year', 'clientdata.demo.age_month', 'clientdata.demo.children', 'clientdata.demo.children_singleparent', 'clientdata.demo.maritalstatus_expand_SINGLE', 'clientdata.demo.maritalstatus_expand_MARRIED', 'clientdata.demo.maritalstatus_expand_DIVORCED', 'clientdata.demo.maritalstatus_expand_WIDOWED', 'clientdata.demo.maritalstatus_expand_newvalue', 'clientdata.demo.maritalstatus_woe']\n",
      "Training Features Shape: (103565, 406)\n",
      "Training Labels Shape: (103565,)\n",
      "Testing Features Shape: (25892, 406)\n",
      "Testing Labels Shape: (25892,)\n",
      "XGBoost Model training completed in 1.07 minutes\n"
     ]
    }
   ],
   "source": [
    "results_dict = train_best_XGB(df, best_params, results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a0fee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rf0': {'classifier': RandomForestClassifier(random_state=42),\n",
       "  'cfm_train': array([[36755,     0],\n",
       "         [    0, 66810]]),\n",
       "  'cfm_test': array([[ 2682,  6452],\n",
       "         [ 1631, 15127]]),\n",
       "  'train_accuracy': 1.0,\n",
       "  'test_accuracy': 0.6878186312374479,\n",
       "  'train F1-score label 1': 1.0,\n",
       "  'train F1-score label 0': 1.0,\n",
       "  'test F1-score label 1': 0.7891592978062968,\n",
       "  'test F1-score label 0': 0.39889938276195436,\n",
       "  'test roc auc score': np.float64(0.7036737409018287),\n",
       "  'best_params': {'bootstrap': True,\n",
       "   'ccp_alpha': 0.0,\n",
       "   'class_weight': None,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_leaf_nodes': None,\n",
       "   'max_samples': None,\n",
       "   'min_impurity_decrease': 0.0,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'min_weight_fraction_leaf': 0.0,\n",
       "   'monotonic_cst': None,\n",
       "   'n_estimators': 100,\n",
       "   'n_jobs': None,\n",
       "   'oob_score': False,\n",
       "   'random_state': 42,\n",
       "   'verbose': 0,\n",
       "   'warm_start': False},\n",
       "  'time_m': 1.809039008617401},\n",
       " 'xgbc0': {'classifier': GridSearchCV(cv=3,\n",
       "               estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                       callbacks=None, colsample_bylevel=None,\n",
       "                                       colsample_bynode=None,\n",
       "                                       colsample_bytree=None, device=None,\n",
       "                                       early_stopping_rounds=None,\n",
       "                                       enable_categorical=False, eval_metric=None,\n",
       "                                       feature_types=None, feature_weights=None,\n",
       "                                       gamma=None, grow_policy=None,\n",
       "                                       importance_type=None,\n",
       "                                       interaction_constraints=Non...\n",
       "                           'learning_rate': [None], 'max_bin': [None],\n",
       "                           'max_cat_threshold': [None],\n",
       "                           'max_cat_to_onehot': [None], 'max_delta_step': [None],\n",
       "                           'max_depth': [None], 'max_leaves': [None],\n",
       "                           'min_child_weight': [None], 'missing': [nan],\n",
       "                           'monotone_constraints': [None],\n",
       "                           'multi_strategy': [None], 'n_estimators': [None],\n",
       "                           'n_jobs': [None], 'num_parallel_tree': [None], ...},\n",
       "               return_train_score=True, scoring='accuracy', verbose=1),\n",
       "  'cfm_train': array([[20665, 16090],\n",
       "         [ 5224, 61586]]),\n",
       "  'cfm_test': array([[ 3685,  5449],\n",
       "         [ 2418, 14340]]),\n",
       "  'train_accuracy': 0.7941968811857287,\n",
       "  'test_accuracy': 0.6961609763633555,\n",
       "  'train F1-score label 1': 0.8524839776864195,\n",
       "  'train F1-score label 0': 0.6597599131600792,\n",
       "  'test F1-score label 1': 0.7847429337565327,\n",
       "  'test F1-score label 0': 0.4836910152917241,\n",
       "  'test roc auc score': np.float64(0.7229549051709006),\n",
       "  'best_params': {'base_score': None,\n",
       "   'booster': None,\n",
       "   'callbacks': None,\n",
       "   'colsample_bylevel': None,\n",
       "   'colsample_bynode': None,\n",
       "   'colsample_bytree': None,\n",
       "   'device': None,\n",
       "   'early_stopping_rounds': None,\n",
       "   'enable_categorical': False,\n",
       "   'eval_metric': None,\n",
       "   'feature_types': None,\n",
       "   'feature_weights': None,\n",
       "   'gamma': None,\n",
       "   'grow_policy': None,\n",
       "   'importance_type': None,\n",
       "   'interaction_constraints': None,\n",
       "   'learning_rate': None,\n",
       "   'max_bin': None,\n",
       "   'max_cat_threshold': None,\n",
       "   'max_cat_to_onehot': None,\n",
       "   'max_delta_step': None,\n",
       "   'max_depth': None,\n",
       "   'max_leaves': None,\n",
       "   'min_child_weight': None,\n",
       "   'missing': nan,\n",
       "   'monotone_constraints': None,\n",
       "   'multi_strategy': None,\n",
       "   'n_estimators': None,\n",
       "   'n_jobs': None,\n",
       "   'num_parallel_tree': None,\n",
       "   'objective': 'binary:logistic',\n",
       "   'random_state': 42,\n",
       "   'reg_alpha': None,\n",
       "   'reg_lambda': None,\n",
       "   'sampling_method': None,\n",
       "   'scale_pos_weight': None,\n",
       "   'subsample': None,\n",
       "   'tree_method': None,\n",
       "   'validate_parameters': None,\n",
       "   'verbosity': None},\n",
       "  'time_m': 0.42970751921335854},\n",
       " 'xgbc_optuna': {'classifier': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                colsample_bylevel=None, colsample_bynode=None,\n",
       "                colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "                enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "                feature_weights=None, gamma=0, grow_policy=None,\n",
       "                importance_type=None, interaction_constraints=None,\n",
       "                learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "                max_cat_to_onehot=None, max_delta_step=None, max_depth=10,\n",
       "                max_leaves=None, min_child_weight=3, missing=nan,\n",
       "                monotone_constraints=None, multi_strategy=None, n_estimators=1000,\n",
       "                n_jobs=None, num_parallel_tree=None, ...),\n",
       "  'cfm_train': array([[19211, 17544],\n",
       "         [ 6118, 60692]]),\n",
       "  'cfm_test': array([[ 3800,  5334],\n",
       "         [ 2328, 14430]]),\n",
       "  'train_accuracy': 0.771525129145947,\n",
       "  'test_accuracy': 0.7040784798393326,\n",
       "  'train F1-score label 1': 0.8368655461026158,\n",
       "  'train F1-score label 0': 0.6188712067521422,\n",
       "  'test F1-score label 1': 0.7902086413668474,\n",
       "  'test F1-score label 0': 0.4979688114270738,\n",
       "  'test roc auc score': np.float64(0.7363490746426682),\n",
       "  'best_params': {'objective': 'binary:logistic',\n",
       "   'base_score': None,\n",
       "   'booster': None,\n",
       "   'callbacks': None,\n",
       "   'colsample_bylevel': None,\n",
       "   'colsample_bynode': None,\n",
       "   'colsample_bytree': 0.8,\n",
       "   'device': None,\n",
       "   'early_stopping_rounds': None,\n",
       "   'enable_categorical': False,\n",
       "   'eval_metric': None,\n",
       "   'feature_types': None,\n",
       "   'feature_weights': None,\n",
       "   'gamma': 0,\n",
       "   'grow_policy': None,\n",
       "   'importance_type': None,\n",
       "   'interaction_constraints': None,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_bin': None,\n",
       "   'max_cat_threshold': None,\n",
       "   'max_cat_to_onehot': None,\n",
       "   'max_delta_step': None,\n",
       "   'max_depth': 10,\n",
       "   'max_leaves': None,\n",
       "   'min_child_weight': 3,\n",
       "   'missing': nan,\n",
       "   'monotone_constraints': None,\n",
       "   'multi_strategy': None,\n",
       "   'n_estimators': 1000,\n",
       "   'n_jobs': None,\n",
       "   'num_parallel_tree': None,\n",
       "   'random_state': None,\n",
       "   'reg_alpha': 100,\n",
       "   'reg_lambda': 10,\n",
       "   'sampling_method': None,\n",
       "   'scale_pos_weight': None,\n",
       "   'subsample': 0.8,\n",
       "   'tree_method': None,\n",
       "   'validate_parameters': None,\n",
       "   'verbosity': None},\n",
       "  'time_m': 0.22830419540405272},\n",
       " 'xgbc_optimized': {'classifier': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                colsample_bylevel=None, colsample_bynode=None,\n",
       "                colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "                enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "                feature_weights=None, gamma=0, grow_policy=None,\n",
       "                importance_type=None, interaction_constraints=None,\n",
       "                learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "                max_cat_to_onehot=None, max_delta_step=None, max_depth=10,\n",
       "                max_leaves=None, min_child_weight=3, missing=nan,\n",
       "                monotone_constraints=None, multi_strategy=None, n_estimators=1000,\n",
       "                n_jobs=None, num_parallel_tree=None, ...),\n",
       "  'cfm_train': array([[15175, 21580],\n",
       "         [ 9098, 57712]]),\n",
       "  'cfm_test': array([[ 3800,  5334],\n",
       "         [ 2328, 14430]]),\n",
       "  'train_accuracy': 0.7037802346352532,\n",
       "  'test_accuracy': 0.7040784798393326,\n",
       "  'train F1-score label 1': 0.7900234083037878,\n",
       "  'train F1-score label 0': 0.4973127089204955,\n",
       "  'test F1-score label 1': 0.7902086413668474,\n",
       "  'test F1-score label 0': 0.4979688114270738,\n",
       "  'test roc auc score': np.float64(0.7363490746426682),\n",
       "  'best_params': {'learning_rate': 0.1,\n",
       "   'max_depth': 10,\n",
       "   'n_estimators': 1000,\n",
       "   'subsample': 0.8,\n",
       "   'colsample_bytree': 0.8,\n",
       "   'gamma': 0,\n",
       "   'min_child_weight': 3,\n",
       "   'reg_alpha': 100,\n",
       "   'reg_lambda': 10},\n",
       "  'time_m': 1.0729696075121562}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eea481c-96eb-4736-aa8b-8ce0bfea1b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results_dict_updated to a pickle file\n",
    "with open('../pickle/4_Model_Optuna/results_dict_updated.pkl', 'wb') as f:\n",
    "    pickle.dump(results_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0ea218",
   "metadata": {},
   "source": [
    "# 7) Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ed955a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rf0': {'best_params': {'bootstrap': True,\n",
      "                         'ccp_alpha': 0.0,\n",
      "                         'class_weight': None,\n",
      "                         'criterion': 'gini',\n",
      "                         'max_depth': None,\n",
      "                         'max_features': 'sqrt',\n",
      "                         'max_leaf_nodes': None,\n",
      "                         'max_samples': None,\n",
      "                         'min_impurity_decrease': 0.0,\n",
      "                         'min_samples_leaf': 1,\n",
      "                         'min_samples_split': 2,\n",
      "                         'min_weight_fraction_leaf': 0.0,\n",
      "                         'monotonic_cst': None,\n",
      "                         'n_estimators': 100,\n",
      "                         'n_jobs': None,\n",
      "                         'oob_score': False,\n",
      "                         'random_state': 42,\n",
      "                         'verbose': 0,\n",
      "                         'warm_start': False},\n",
      "         'cfm_test': array([[ 2682,  6452],\n",
      "       [ 1631, 15127]]),\n",
      "         'cfm_train': array([[36755,     0],\n",
      "       [    0, 66810]]),\n",
      "         'classifier': RandomForestClassifier(random_state=42),\n",
      "         'test F1-score label 0': 0.39889938276195436,\n",
      "         'test F1-score label 1': 0.7891592978062968,\n",
      "         'test roc auc score': np.float64(0.7036737409018287),\n",
      "         'test_accuracy': 0.6878186312374479,\n",
      "         'time_m': 1.809039008617401,\n",
      "         'train F1-score label 0': 1.0,\n",
      "         'train F1-score label 1': 1.0,\n",
      "         'train_accuracy': 1.0},\n",
      " 'xgbc0': {'best_params': {'base_score': None,\n",
      "                           'booster': None,\n",
      "                           'callbacks': None,\n",
      "                           'colsample_bylevel': None,\n",
      "                           'colsample_bynode': None,\n",
      "                           'colsample_bytree': None,\n",
      "                           'device': None,\n",
      "                           'early_stopping_rounds': None,\n",
      "                           'enable_categorical': False,\n",
      "                           'eval_metric': None,\n",
      "                           'feature_types': None,\n",
      "                           'feature_weights': None,\n",
      "                           'gamma': None,\n",
      "                           'grow_policy': None,\n",
      "                           'importance_type': None,\n",
      "                           'interaction_constraints': None,\n",
      "                           'learning_rate': None,\n",
      "                           'max_bin': None,\n",
      "                           'max_cat_threshold': None,\n",
      "                           'max_cat_to_onehot': None,\n",
      "                           'max_delta_step': None,\n",
      "                           'max_depth': None,\n",
      "                           'max_leaves': None,\n",
      "                           'min_child_weight': None,\n",
      "                           'missing': nan,\n",
      "                           'monotone_constraints': None,\n",
      "                           'multi_strategy': None,\n",
      "                           'n_estimators': None,\n",
      "                           'n_jobs': None,\n",
      "                           'num_parallel_tree': None,\n",
      "                           'objective': 'binary:logistic',\n",
      "                           'random_state': 42,\n",
      "                           'reg_alpha': None,\n",
      "                           'reg_lambda': None,\n",
      "                           'sampling_method': None,\n",
      "                           'scale_pos_weight': None,\n",
      "                           'subsample': None,\n",
      "                           'tree_method': None,\n",
      "                           'validate_parameters': None,\n",
      "                           'verbosity': None},\n",
      "           'cfm_test': array([[ 3685,  5449],\n",
      "       [ 2418, 14340]]),\n",
      "           'cfm_train': array([[20665, 16090],\n",
      "       [ 5224, 61586]]),\n",
      "           'classifier': GridSearchCV(cv=3,\n",
      "             estimator=XGBClassifier(base_score=None, booster=None,\n",
      "                                     callbacks=None, colsample_bylevel=None,\n",
      "                                     colsample_bynode=None,\n",
      "                                     colsample_bytree=None, device=None,\n",
      "                                     early_stopping_rounds=None,\n",
      "                                     enable_categorical=False, eval_metric=None,\n",
      "                                     feature_types=None, feature_weights=None,\n",
      "                                     gamma=None, grow_policy=None,\n",
      "                                     importance_type=None,\n",
      "                                     interaction_constraints=Non...\n",
      "                         'learning_rate': [None], 'max_bin': [None],\n",
      "                         'max_cat_threshold': [None],\n",
      "                         'max_cat_to_onehot': [None], 'max_delta_step': [None],\n",
      "                         'max_depth': [None], 'max_leaves': [None],\n",
      "                         'min_child_weight': [None], 'missing': [nan],\n",
      "                         'monotone_constraints': [None],\n",
      "                         'multi_strategy': [None], 'n_estimators': [None],\n",
      "                         'n_jobs': [None], 'num_parallel_tree': [None], ...},\n",
      "             return_train_score=True, scoring='accuracy', verbose=1),\n",
      "           'test F1-score label 0': 0.4836910152917241,\n",
      "           'test F1-score label 1': 0.7847429337565327,\n",
      "           'test roc auc score': np.float64(0.7229549051709006),\n",
      "           'test_accuracy': 0.6961609763633555,\n",
      "           'time_m': 0.42970751921335854,\n",
      "           'train F1-score label 0': 0.6597599131600792,\n",
      "           'train F1-score label 1': 0.8524839776864195,\n",
      "           'train_accuracy': 0.7941968811857287},\n",
      " 'xgbc_optimized': {'best_params': {'colsample_bytree': 0.8,\n",
      "                                    'gamma': 0,\n",
      "                                    'learning_rate': 0.1,\n",
      "                                    'max_depth': 10,\n",
      "                                    'min_child_weight': 3,\n",
      "                                    'n_estimators': 1000,\n",
      "                                    'reg_alpha': 100,\n",
      "                                    'reg_lambda': 10,\n",
      "                                    'subsample': 0.8},\n",
      "                    'cfm_test': array([[ 3800,  5334],\n",
      "       [ 2328, 14430]]),\n",
      "                    'cfm_train': array([[15175, 21580],\n",
      "       [ 9098, 57712]]),\n",
      "                    'classifier': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              feature_weights=None, gamma=0, grow_policy=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,\n",
      "              max_leaves=None, min_child_weight=3, missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=1000,\n",
      "              n_jobs=None, num_parallel_tree=None, ...),\n",
      "                    'test F1-score label 0': 0.4979688114270738,\n",
      "                    'test F1-score label 1': 0.7902086413668474,\n",
      "                    'test roc auc score': np.float64(0.7363490746426682),\n",
      "                    'test_accuracy': 0.7040784798393326,\n",
      "                    'time_m': 1.0729696075121562,\n",
      "                    'train F1-score label 0': 0.4973127089204955,\n",
      "                    'train F1-score label 1': 0.7900234083037878,\n",
      "                    'train_accuracy': 0.7037802346352532},\n",
      " 'xgbc_optuna': {'best_params': {'base_score': None,\n",
      "                                 'booster': None,\n",
      "                                 'callbacks': None,\n",
      "                                 'colsample_bylevel': None,\n",
      "                                 'colsample_bynode': None,\n",
      "                                 'colsample_bytree': 0.8,\n",
      "                                 'device': None,\n",
      "                                 'early_stopping_rounds': None,\n",
      "                                 'enable_categorical': False,\n",
      "                                 'eval_metric': None,\n",
      "                                 'feature_types': None,\n",
      "                                 'feature_weights': None,\n",
      "                                 'gamma': 0,\n",
      "                                 'grow_policy': None,\n",
      "                                 'importance_type': None,\n",
      "                                 'interaction_constraints': None,\n",
      "                                 'learning_rate': 0.1,\n",
      "                                 'max_bin': None,\n",
      "                                 'max_cat_threshold': None,\n",
      "                                 'max_cat_to_onehot': None,\n",
      "                                 'max_delta_step': None,\n",
      "                                 'max_depth': 10,\n",
      "                                 'max_leaves': None,\n",
      "                                 'min_child_weight': 3,\n",
      "                                 'missing': nan,\n",
      "                                 'monotone_constraints': None,\n",
      "                                 'multi_strategy': None,\n",
      "                                 'n_estimators': 1000,\n",
      "                                 'n_jobs': None,\n",
      "                                 'num_parallel_tree': None,\n",
      "                                 'objective': 'binary:logistic',\n",
      "                                 'random_state': None,\n",
      "                                 'reg_alpha': 100,\n",
      "                                 'reg_lambda': 10,\n",
      "                                 'sampling_method': None,\n",
      "                                 'scale_pos_weight': None,\n",
      "                                 'subsample': 0.8,\n",
      "                                 'tree_method': None,\n",
      "                                 'validate_parameters': None,\n",
      "                                 'verbosity': None},\n",
      "                 'cfm_test': array([[ 3800,  5334],\n",
      "       [ 2328, 14430]]),\n",
      "                 'cfm_train': array([[19211, 17544],\n",
      "       [ 6118, 60692]]),\n",
      "                 'classifier': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              feature_weights=None, gamma=0, grow_policy=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,\n",
      "              max_leaves=None, min_child_weight=3, missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=1000,\n",
      "              n_jobs=None, num_parallel_tree=None, ...),\n",
      "                 'test F1-score label 0': 0.4979688114270738,\n",
      "                 'test F1-score label 1': 0.7902086413668474,\n",
      "                 'test roc auc score': np.float64(0.7363490746426682),\n",
      "                 'test_accuracy': 0.7040784798393326,\n",
      "                 'time_m': 0.22830419540405272,\n",
      "                 'train F1-score label 0': 0.6188712067521422,\n",
      "                 'train F1-score label 1': 0.8368655461026158,\n",
      "                 'train_accuracy': 0.771525129145947}}\n"
     ]
    }
   ],
   "source": [
    "pprint(results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7c54df",
   "metadata": {},
   "source": [
    "# 7) Compile results: AUC, Accuracy and Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cec2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark RandomForest - AUC/accuracy score: 0.7037 / 0.6878 @ 1.81 minutes\n",
      "Benchmark XGBoost - AUC/accuracy score: 0.723 / 0.6962 @ 0.43 minutes\n",
      "XGBoost w/ Optuna - AUC/accuracy score: 0.7363 / 0.7041 @ 0.23 minutes\n",
      "Optimized XGBoost w/ Optuna - AUC/accuracy score: 0.7363 / 0.7041 @ 1.07 minutes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#printing benchmark, iterative grid search and randomized search ROC AUC / accuracy scores (test data set)\n",
    "print(f\"Benchmark RandomForest - AUC/accuracy score: {np.round(results_dict['rf0']['test roc auc score'],4)} / {np.round(results_dict['rf0']['test_accuracy'],4)} @ {np.round(results_dict['rf0']['time_m'],2)} minutes\")\n",
    "print(f\"Benchmark XGBoost - AUC/accuracy score: {np.round(results_dict['xgbc0']['test roc auc score'],4)} / {np.round(results_dict['xgbc0']['test_accuracy'],4)} @ {np.round(results_dict['xgbc0']['time_m'],2)} minutes\")\n",
    "print(f\"XGBoost w/ Optuna - AUC/accuracy score: {np.round(results_dict['xgbc_optuna']['test roc auc score'],4)} / {np.round(results_dict['xgbc_optuna']['test_accuracy'],4)} @ {np.round(results_dict['xgbc_optuna']['time_m'],2)} minutes\")\n",
    "print(f\"Optimized XGBoost w/ Optuna - AUC/accuracy score: {np.round(results_dict['xgbc_optimized']['test roc auc score'],4)} / {np.round(results_dict['xgbc_optimized']['test_accuracy'],4)} @ {np.round(results_dict['xgbc_optimized']['time_m'],2)} minutes\")\n",
    "\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acef8e0e-e6e6-4fc7-97c2-88eaf7292e81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
